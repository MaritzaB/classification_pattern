{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 7. Experimentacion\n",
    "\n",
    "Esta tarea consiste en llevar a cabo la experimentación de diversos\n",
    "clasificadores sobre una variedad de datasets. Se reportarán los resultados y,\n",
    "posteriormente cuando tengamos la clase de significancia estadística, haremos el\n",
    "análisis de los clasificadores y si hay un ganador cuál de ellos sería.\n",
    "\n",
    "Las instrucciones se detallan a continuación:\n",
    "\n",
    "1. Buscar varios datasets (7, 8, 10, etc.) que cumplan con una condición: deben\n",
    "   tener alguna característica en común. ¿Qué característica en común? Hay\n",
    "   varias cosas que pueden satisfacer esta condición, por ejemplo, que traten el\n",
    "   mismo problema (e.g. diagnósticos médicos aunque sean de diferente\n",
    "   enfermedad), que tengan muchas más variables que instancias (maldición de la\n",
    "   dimensionalidad), que todos sean de más de 3 clases, que sus clases estén\n",
    "   desbalanceadas, entre otras cosas que ustedes puedan identificar. La idea es\n",
    "   que dichos datasets puedan ser identificados en el mismo contexto.\n",
    "\n",
    "2. Llevar a cabo la clasificación, utilizando scikit-learn, aplicando los\n",
    "   clasificadores que hemos visto y algunos otros de su predilección. Para\n",
    "   realizar la clasificación, deben emplear algún método de validación cruzada\n",
    "   (k-fold cross-validation, o leave-one-out, dependiendo la cantidad de datos).\n",
    "   Asimismo, deberán reportar los resultados utilizando el balanced accuracy,\n",
    "   sensibilidad y especificidad (juntas), o bien el área bajo la curva roc (AUC\n",
    "   ROC).\n",
    "\n",
    "3. Posteriormente realizaremos alguna prueba de significancia estadística (cuyo\n",
    "   tema veremos al regreso de vacaciones), con la finalidad de conocer si\n",
    "   existen diferencias estadísticamente significativas entre los clasificadores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos de medidas morfológicas de animales o plantas para inferir especie o sexo.\n",
    "\n",
    "1. [Abalone dataset](https://archive-beta.ics.uci.edu/dataset/1/abalone)\n",
    "\n",
    "1. [Birds\n",
    "   bones dataset](https://www.kaggle.com/datasets/zhangjuefei/birds-bones-and-living-habits)\n",
    "\n",
    "1. [Penguins dataset](https://archive-beta.ics.uci.edu/dataset/690/palmer+penguins-3)\n",
    "\n",
    "1. [Pokemon_dataset](https://www.kaggle.com/datasets/cristobalmitchell/pokedex)\n",
    "\n",
    "1. [Sloths dataset](https://www.kaggle.com/datasets/bertiemackie/sloth-species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "abalones = pd.read_csv(\"../datasets/abalone.csv\")\n",
    "print(abalones.shape)\n",
    "abalones_ft = abalones.loc[:,['Shell_length', 'Shell_diameter', 'Height', 'Whole_weight',\n",
    "       'Shucked_weight', 'Viscera_weight', 'Shell_weight',]]\n",
    "abalones_tg = abalones[['Sex']]\n",
    "\n",
    "birds = pd.read_csv(\"../datasets/bird.csv\")\n",
    "print(birds.shape)\n",
    "birds_ft = birds.loc[:,['Humerus_length', 'Humerus_diameter', 'Ulna_length',\n",
    "       'Ulna_diamater', 'Femur_length', 'Femur_diameter', 'Tibiotarsus_length',\n",
    "       'Tibiotarsus_diameter', 'Tarsometatarsus_length',\n",
    "       'Tarsometatarsus_diameter',]]\n",
    "birds_tg = birds[['Species_group']]\n",
    "\n",
    "penguins = pd.read_csv(\"../datasets/penguins.csv\")\n",
    "print(penguins.shape)\n",
    "penguins_ft = penguins.loc[:,['Culmen_Length_mm', 'Culmen_Depth_mm', 'Flipper_Length_', 'Body_Massgr', ]]\n",
    "penguins_tg = penguins[['Species']]\n",
    "\n",
    "#pokemon = pd.read_csv(\"../datasets/pokemon.csv\")\n",
    "\n",
    "sloths = pd.read_csv(\"../datasets/sloth_data.csv\")\n",
    "print(sloths.shape)\n",
    "sloths_ft = sloths.loc[:,['Claw_length_cm', 'Size_cm', 'Tail_length_cm', 'Weight_kg', ]]\n",
    "sloths_tg = sloths[['Sub_specie']]\n",
    "\n",
    "datasets = [\n",
    "    (abalones_ft, abalones_tg),\n",
    "    (birds_ft, birds_tg),\n",
    "    (penguins_ft, penguins_tg),\n",
    "    (sloths_ft, sloths_tg)\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación cruzada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "lr = LogisticRegression()\n",
    "dtc = DecisionTreeClassifier()\n",
    "svc = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "classifiers.append(lr)\n",
    "classifiers.append(dtc)\n",
    "classifiers.append(svc)\n",
    "classifiers.append(knn)\n",
    "classifiers.append(rfc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación cruzada (Hold Out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class DatasetSplitter:\n",
    "    def __init__(self, test_size, random_state=1111):\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def split_datasets(self, datasets):\n",
    "        train_datasets = []\n",
    "        test_datasets = []\n",
    "        for data, target in datasets:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=self.test_size, random_state=self.random_state)\n",
    "            train_datasets.append((X_train, y_train))\n",
    "            test_datasets.append((X_test, y_test))\n",
    "        return train_datasets, test_datasets\n",
    "    \n",
    "splitter = DatasetSplitter(test_size=0.2, random_state=42)\n",
    "train_datasets, test_datasets = splitter.split_datasets(datasets)\n",
    "\n",
    "# Print the training and testing subsets for each dataset\n",
    "print('---Datos de entrenamiento---')\n",
    "for i, (X_train, y_train) in enumerate(train_datasets):\n",
    "    print(f\"Dataset {i+1} training data:\\n{X_train.shape}\")\n",
    "    print(f\"Dataset {i+1} training target:\\n{y_train.shape}\")\n",
    "\n",
    "print('---Datos de validación---')\n",
    "for i, (X_test, y_test) in enumerate(test_datasets):\n",
    "    print(f\"Dataset {i+1} testing data:\\n{X_test.shape}\")\n",
    "    print(f\"Dataset {i+1} testing target:\\n{y_test.shape}\")\n",
    "\n",
    "#print(train_datasets)\n",
    "#plt.scatter(X_train[0].iloc[:,0],X_train_i[0].iloc[:,1], alpha=0.5)\n",
    "#plt.scatter(X_test[0].iloc[:,0],X_test[0].iloc[:,1], alpha=0.5)\n",
    "#plt.grid(color='#EEEEEE')\n",
    "#plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
